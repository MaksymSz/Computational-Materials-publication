{
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 9166059,
     "sourceType": "datasetVersion",
     "datasetId": 5538395
    },
    {
     "sourceId": 9166060,
     "sourceType": "datasetVersion",
     "datasetId": 5538396
    },
    {
     "sourceId": 9166075,
     "sourceType": "datasetVersion",
     "datasetId": 5538408
    },
    {
     "sourceId": 9166076,
     "sourceType": "datasetVersion",
     "datasetId": 5538409
    },
    {
     "sourceId": 9166077,
     "sourceType": "datasetVersion",
     "datasetId": 5538410
    },
    {
     "sourceId": 9166085,
     "sourceType": "datasetVersion",
     "datasetId": 5538417
    },
    {
     "sourceId": 9166086,
     "sourceType": "datasetVersion",
     "datasetId": 5538418
    }
   ],
   "dockerImageVersionId": 30747,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 416.439474,
   "end_time": "2024-08-13T11:21:16.783646",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-13T11:14:20.344172",
   "version": "2.5.0"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Dataset settings",
   "metadata": {
    "papermill": {
     "duration": 0.005633,
     "end_time": "2024-08-13T11:14:23.218231",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.212598",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "C = 3\np_limit = 1\nEPOCHS=60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:23.230577Z",
     "iopub.status.busy": "2024-08-13T11:14:23.229741Z",
     "iopub.status.idle": "2024-08-13T11:14:23.240836Z",
     "shell.execute_reply": "2024-08-13T11:14:23.240078Z"
    },
    "papermill": {
     "duration": 0.019259,
     "end_time": "2024-08-13T11:14:23.242665",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.223406",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "input_names = '2-3 4-6 7-9 10-15 20-25 30-35 40-50'.split()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hp0 = {\n",
    "    'input_shape': (15*15,),\n",
    "    'activation': 'relu',\n",
    "    'first_dense_units': 500,\n",
    "    'second_dense_units': 1100,\n",
    "    'third_dense_units': 500,\n",
    "    'kernel_initializer': 'lecun_uniform',\n",
    "    'learning_rate': 0.0005875310943952402,\n",
    "    'optimizer': 'nadam',\n",
    "    'dropout_ratio': 0.01,\n",
    "    'loss': 'mse'\n",
    "}"
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:23.253979Z",
     "iopub.status.busy": "2024-08-13T11:14:23.253478Z",
     "iopub.status.idle": "2024-08-13T11:14:23.260285Z",
     "shell.execute_reply": "2024-08-13T11:14:23.259469Z"
    },
    "papermill": {
     "duration": 0.01436,
     "end_time": "2024-08-13T11:14:23.262180",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.247820",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Data downloading and organizing",
   "metadata": {
    "papermill": {
     "duration": 0.004729,
     "end_time": "2024-08-13T11:14:23.272096",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.267367",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "import os\n\nos.mkdir('./logs')\nos.mkdir('./logs/neural')",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:23.282961Z",
     "iopub.status.busy": "2024-08-13T11:14:23.282670Z",
     "iopub.status.idle": "2024-08-13T11:14:23.286911Z",
     "shell.execute_reply": "2024-08-13T11:14:23.286028Z"
    },
    "papermill": {
     "duration": 0.01156,
     "end_time": "2024-08-13T11:14:23.288686",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.277126",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "os.mkdir('./figs')",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:23.300495Z",
     "iopub.status.busy": "2024-08-13T11:14:23.299709Z",
     "iopub.status.idle": "2024-08-13T11:14:23.303608Z",
     "shell.execute_reply": "2024-08-13T11:14:23.302859Z"
    },
    "papermill": {
     "duration": 0.011599,
     "end_time": "2024-08-13T11:14:23.305488",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.293889",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Useful functions:\n* bulding model for `super_model architecture`\n* OneCycleScheduler\n* data preparation\n* finding `learning_rate`",
   "metadata": {
    "papermill": {
     "duration": 0.004779,
     "end_time": "2024-08-13T11:14:23.315563",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.310784",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "PI_RESOLUTION = 50\n\n\ndef prepare_inputs(pi_resolution):\n    model_inputs = {\n        'current': slice(0, 1),\n    }\n\n    i = 0\n    for k in range(3):\n        for p in ['a', 'b', 'c']:\n            model_inputs[f'b{k}_p{p}'] = slice(i * pi_resolution ** 2 + 1, (i + 1) * pi_resolution ** 2 + 1)\n            i += 1\n\n    return model_inputs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:23.326683Z",
     "iopub.status.busy": "2024-08-13T11:14:23.326390Z",
     "iopub.status.idle": "2024-08-13T11:14:23.332092Z",
     "shell.execute_reply": "2024-08-13T11:14:23.331266Z"
    },
    "papermill": {
     "duration": 0.013333,
     "end_time": "2024-08-13T11:14:23.333986",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.320653",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import tensorflow as tf\n\n\nclass OneCycleScheduler(tf.keras.callbacks.Callback):\n    def __init__(self, iterations, max_lr=1e-3, start_lr=None,\n                 last_iterations=None, last_lr=None):\n        self.iterations = iterations\n        self.max_lr = max_lr\n        self.start_lr = start_lr or max_lr / 10\n        self.last_iterations = last_iterations or iterations // 10 + 1\n        self.half_iteration = (iterations - self.last_iterations) // 2\n        self.last_lr = last_lr or self.start_lr / 1000\n        self.iteration = 0\n\n    def _interpolate(self, iter1, iter2, lr1, lr2):\n        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n\n    def on_batch_begin(self, batch, logs):\n        if self.iteration < self.half_iteration:\n            lr = self._interpolate(0, self.half_iteration, self.start_lr,\n                                   self.max_lr)\n        elif self.iteration < 2 * self.half_iteration:\n            lr = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n                                   self.max_lr, self.start_lr)\n        else:\n            lr = self._interpolate(2 * self.half_iteration, self.iterations,\n                                   self.start_lr, self.last_lr)\n        self.iteration += 1\n        self.model.optimizer.learning_rate = lr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:23.344856Z",
     "iopub.status.busy": "2024-08-13T11:14:23.344575Z",
     "iopub.status.idle": "2024-08-13T11:14:36.664055Z",
     "shell.execute_reply": "2024-08-13T11:14:36.663144Z"
    },
    "papermill": {
     "duration": 13.327617,
     "end_time": "2024-08-13T11:14:36.666594",
     "exception": false,
     "start_time": "2024-08-13T11:14:23.338977",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "current_lr = 3.2e-05\n",
    "from keras.layers import Dropout, AlphaDropout\n",
    "\n",
    "def build_drop_super_model_kt(hp):\n",
    "    \"\"\"Function that builds `super_model_architecture`\"\"\"\n",
    "    # hyperparams\n",
    "    \n",
    "    _input_shape = hp[\"input_shape\"]\n",
    "    _activation = hp[\"activation\"]\n",
    "    first_dense_neurons = hp[\"first_dense_units\"]\n",
    "    second_dense_neurons = hp[\"second_dense_units\"]\n",
    "    third_dense_neurons = hp[\"third_dense_units\"]\n",
    "\n",
    "    _first_dense_units = first_dense_neurons\n",
    "    _second_dense_units = second_dense_neurons\n",
    "    _third_dense_units = third_dense_neurons\n",
    "\n",
    "    _kernel_initializer = hp[\"kernel_initializer\"]\n",
    "    learning_rate = hp[\"learning_rate\"]\n",
    "    optimizer = hp[\"optimizer\"]\n",
    "    _dropout_rate = hp[\"dropout_ratio\"]\n",
    "\n",
    "    if 'adam' == optimizer:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimzier = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "    global current_lr\n",
    "    current_lr = learning_rate\n",
    "\n",
    "    if _activation in ('lecun_normal', 'lecun_uniform'):\n",
    "        _dropout = AlphaDropout\n",
    "    else:\n",
    "        _dropout = Dropout\n",
    "\n",
    "    # input layers\n",
    "    b0_pa = tf.keras.layers.Input(shape=_input_shape, name='b0_pa')\n",
    "    b0_pb = tf.keras.layers.Input(shape=_input_shape, name='b0_pb')\n",
    "    b0_pc = tf.keras.layers.Input(shape=_input_shape, name='b0_pc')\n",
    "\n",
    "    b1_pa = tf.keras.layers.Input(shape=_input_shape, name='b1_pa')\n",
    "    b1_pb = tf.keras.layers.Input(shape=_input_shape, name='b1_pb')\n",
    "    b1_pc = tf.keras.layers.Input(shape=_input_shape, name='b1_pc')\n",
    "\n",
    "    b2_pa = tf.keras.layers.Input(shape=_input_shape, name='b2_pa')\n",
    "    b2_pb = tf.keras.layers.Input(shape=_input_shape, name='b2_pb')\n",
    "    b2_pc = tf.keras.layers.Input(shape=_input_shape, name='b2_pc')\n",
    "\n",
    "    # first dense\n",
    "    b0_pa_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b0_pa_dense')(b0_pa))\n",
    "    b0_pb_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b0_pb_dense')(b0_pb))\n",
    "    b0_pc_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b0_pc_dense')(b0_pc))\n",
    "    b1_pa_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b1_pa_dense')(b1_pa))\n",
    "    b1_pb_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b1_pb_dense')(b1_pb))\n",
    "    b1_pc_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b1_pc_dense')(b1_pc))\n",
    "    b2_pa_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b2_pa_dense')(b2_pa))\n",
    "    b2_pb_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b2_pb_dense')(b2_pb))\n",
    "    b2_pc_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_first_dense_units, activation=_activation,\n",
    "                                                               kernel_initializer=_kernel_initializer,\n",
    "                                                               name='b2_pc_dense')(b2_pc))\n",
    "\n",
    "    # first concatenations\n",
    "    c0 = tf.keras.layers.Concatenate(name='concat_b0')([b0_pa_next, b0_pb_next, b0_pc_next])\n",
    "    c1 = tf.keras.layers.Concatenate(name='concat_b1')([b1_pa_next, b1_pb_next, b1_pc_next])\n",
    "    c2 = tf.keras.layers.Concatenate(name='concat_b2')([b2_pa_next, b2_pb_next, b2_pc_next])\n",
    "\n",
    "    # second dense\n",
    "    c0_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_second_dense_units, activation=_activation,\n",
    "                                                            kernel_initializer=_kernel_initializer, name='c0_dense')(\n",
    "        c0))\n",
    "    c1_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_second_dense_units, activation=_activation,\n",
    "                                                            kernel_initializer=_kernel_initializer, name='c1_dense')(\n",
    "        c1))\n",
    "    c2_next = _dropout(_dropout_rate)(tf.keras.layers.Dense(units=_second_dense_units, activation=_activation,\n",
    "                                                            kernel_initializer=_kernel_initializer, name='c2_dense')(\n",
    "        c2))\n",
    "\n",
    "    # second concatenations\n",
    "    current = tf.keras.layers.Input(shape=(1,), name='current')\n",
    "    c_last = tf.keras.layers.Concatenate(name='concat_last')([current, c0_next, c1_next, c2_next])\n",
    "\n",
    "    # third dense\n",
    "    c_last_dense = tf.keras.layers.Dense(units=_third_dense_units, activation=_activation,\n",
    "                                         kernel_initializer=_kernel_initializer, name='c_last_dense')(c_last)\n",
    "    # output\n",
    "    out = tf.keras.layers.Dense(units=1, name='output')(c_last_dense)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[current, b0_pa, b0_pb, b0_pc, b1_pa, b1_pb, b1_pc, b2_pa, b2_pb, b2_pc],\n",
    "                           outputs=[out])\n",
    "\n",
    "    model.compile(loss=hp[\"loss\"],\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanSquaredError()]\n",
    "                  )\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:36.680651Z",
     "iopub.status.busy": "2024-08-13T11:14:36.679793Z",
     "iopub.status.idle": "2024-08-13T11:14:37.844031Z",
     "shell.execute_reply": "2024-08-13T11:14:37.843198Z"
    },
    "papermill": {
     "duration": 1.174459,
     "end_time": "2024-08-13T11:14:37.846815",
     "exception": false,
     "start_time": "2024-08-13T11:14:36.672356",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Data preparation",
   "metadata": {
    "papermill": {
     "duration": 0.005139,
     "end_time": "2024-08-13T11:14:37.857683",
     "exception": false,
     "start_time": "2024-08-13T11:14:37.852544",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "os.listdir('../input')",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:37.869639Z",
     "iopub.status.busy": "2024-08-13T11:14:37.869308Z",
     "iopub.status.idle": "2024-08-13T11:14:37.876627Z",
     "shell.execute_reply": "2024-08-13T11:14:37.875800Z"
    },
    "papermill": {
     "duration": 0.015744,
     "end_time": "2024-08-13T11:14:37.878696",
     "exception": false,
     "start_time": "2024-08-13T11:14:37.862952",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.utils import shuffle\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:37.890278Z",
     "iopub.status.busy": "2024-08-13T11:14:37.890010Z",
     "iopub.status.idle": "2024-08-13T11:14:37.894749Z",
     "shell.execute_reply": "2024-08-13T11:14:37.894007Z"
    },
    "papermill": {
     "duration": 0.012704,
     "end_time": "2024-08-13T11:14:37.896558",
     "exception": false,
     "start_time": "2024-08-13T11:14:37.883854",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "best_evals = dict()",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:37.908430Z",
     "iopub.status.busy": "2024-08-13T11:14:37.908164Z",
     "iopub.status.idle": "2024-08-13T11:14:37.911898Z",
     "shell.execute_reply": "2024-08-13T11:14:37.911114Z"
    },
    "papermill": {
     "duration": 0.012033,
     "end_time": "2024-08-13T11:14:37.913977",
     "exception": false,
     "start_time": "2024-08-13T11:14:37.901944",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def fine_tune(dataset_name, res):\n",
    "    if res in {2, 3}:\n",
    "        path_name = input_names[0]\n",
    "    elif res in {4, 5, 6}:\n",
    "        path_name = input_names[1]\n",
    "    elif res in {7, 8, 9}:\n",
    "        path_name = input_names[2]\n",
    "    elif res in {10, 15}:\n",
    "        path_name = input_names[3]\n",
    "    elif res in {20, 25}:\n",
    "        path_name = input_names[4]\n",
    "    elif res in {30, 35}:\n",
    "        path_name = input_names[5]\n",
    "    elif res in {40, 50}:\n",
    "        path_name = input_names[6]\n",
    "    else:\n",
    "        path_name = 'ERROR'\n",
    "        \n",
    "    datapath = f'../input/neumann-v3-{path_name}/{dataset_name}__400_data_train.pkl'\n",
    "    targetpath = f'../input/neumann-v3-{path_name}/{dataset_name}__400_target_train.pkl'\n",
    "\n",
    "    data = pd.read_pickle(datapath).to_numpy()\n",
    "    target = pd.read_pickle(targetpath).to_numpy().ravel()\n",
    "\n",
    "    X_valid = pd.read_pickle(datapath.replace('train', 'test')).to_numpy()\n",
    "    y_valid = pd.read_pickle(targetpath.replace('train', 'test')).to_numpy().ravel()\n",
    "    \n",
    "    X_train, y_train = shuffle(data, target, random_state=42)\n",
    "    X_valid, y_valid = shuffle(X_valid, y_valid, random_state=42)\n",
    "\n",
    "    inputs_slices = prepare_inputs(res)\n",
    "\n",
    "    input_data = [\n",
    "        X_train[:, inputs_slices['current']],\n",
    "        X_train[:, inputs_slices['b0_pa']],\n",
    "        X_train[:, inputs_slices['b0_pb']],\n",
    "        X_train[:, inputs_slices['b0_pc']],\n",
    "        X_train[:, inputs_slices['b1_pa']],\n",
    "        X_train[:, inputs_slices['b1_pb']],\n",
    "        X_train[:, inputs_slices['b1_pc']],\n",
    "        X_train[:, inputs_slices['b2_pa']],\n",
    "        X_train[:, inputs_slices['b2_pb']],\n",
    "        X_train[:, inputs_slices['b2_pc']],\n",
    "    ]\n",
    "\n",
    "    input_valid = [\n",
    "        X_valid[:, inputs_slices['current']],\n",
    "        X_valid[:, inputs_slices['b0_pa']],\n",
    "        X_valid[:, inputs_slices['b0_pb']],\n",
    "        X_valid[:, inputs_slices['b0_pc']],\n",
    "        X_valid[:, inputs_slices['b1_pa']],\n",
    "        X_valid[:, inputs_slices['b1_pb']],\n",
    "        X_valid[:, inputs_slices['b1_pc']],\n",
    "        X_valid[:, inputs_slices['b2_pa']],\n",
    "        X_valid[:, inputs_slices['b2_pb']],\n",
    "        X_valid[:, inputs_slices['b2_pc']],\n",
    "    ]\n",
    "\n",
    "    assert all(x is not None for x in input_data), \"Found None in input_data\"\n",
    "    \n",
    "    if not os.path.exists(f'./logs/neural/{dataset_name}'):\n",
    "        os.mkdir(f'./logs/neural/{dataset_name}')\n",
    "\n",
    "    def get_run_logdir(root_logdir=f'./logs/neural/{dataset_name}'):\n",
    "        return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    n_epochs = EPOCHS\n",
    "    \n",
    "    hyperparameters_set = [hp0, hp0, hp0, hp0, hp0]\n",
    "    \n",
    "    model_eval = []\n",
    "    for idx, hp in enumerate(hyperparameters_set):\n",
    "        tb = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(f'./logs/neural/{dataset_name}_{idx}'))\n",
    "                                     \n",
    "        model = build_drop_super_model_kt(hp)\n",
    "        \n",
    "        \n",
    "        onecycle = OneCycleScheduler(math.ceil(X_train.shape[0] / 32) * n_epochs, max_lr=current_lr)\n",
    "        history = model.fit(input_data, y_train,\n",
    "                  epochs=n_epochs,\n",
    "                  callbacks=[onecycle, tb])\n",
    "        \n",
    "        model.save(f'{dataset_name}_{idx}.keras')\n",
    "\n",
    "        model_eval.append(model.evaluate(input_valid, y_valid))\n",
    "\n",
    "    global best_evals\n",
    "    best_evals[dataset_name] = model_eval\n",
    "    \n",
    "    K.clear_session()\n",
    "    with open(f'./working/checkpoint__{int(time.time())}.pkl', 'wb') as fn:\n",
    "        pickle.dump(best_evals, fn)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.025386,
     "end_time": "2024-08-13T11:14:37.944861",
     "exception": false,
     "start_time": "2024-08-13T11:14:37.919475",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-08-13T13:11:16.128285Z",
     "iopub.execute_input": "2024-08-13T13:11:16.128637Z",
     "iopub.status.idle": "2024-08-13T13:11:16.153154Z",
     "shell.execute_reply.started": "2024-08-13T13:11:16.128610Z",
     "shell.execute_reply": "2024-08-13T13:11:16.152122Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for C in [3]:\n    for p in [1]:\n        for res in [50]:\n            name = f'{res}_005Kusano{C}-{p}'\n            hp0['input_shape'] = (res*res,)\n            fine_tune(name, res)\n            print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:14:37.956988Z",
     "iopub.status.busy": "2024-08-13T11:14:37.956676Z",
     "iopub.status.idle": "2024-08-13T11:21:11.638376Z",
     "shell.execute_reply": "2024-08-13T11:21:11.637589Z"
    },
    "papermill": {
     "duration": 393.69022,
     "end_time": "2024-08-13T11:21:11.640569",
     "exception": false,
     "start_time": "2024-08-13T11:14:37.950349",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for key, val in best_evals.items():\n    print(f'{key}: {val}')",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T11:21:12.606141Z",
     "iopub.status.busy": "2024-08-13T11:21:12.605782Z",
     "iopub.status.idle": "2024-08-13T11:21:12.611807Z",
     "shell.execute_reply": "2024-08-13T11:21:12.610595Z"
    },
    "papermill": {
     "duration": 0.472768,
     "end_time": "2024-08-13T11:21:12.614017",
     "exception": false,
     "start_time": "2024-08-13T11:21:12.141249",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(f'./working/models_evals.pkl', 'wb') as fn:\n",
    "    pickle.dump(best_evals, fn)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
